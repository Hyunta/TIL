# 데브원영 아파치 카프카 입문

- 데이터 전송라인이 많아지면 프로토콜의 파편화가 심해진다

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/5489bc18-d818-4151-a088-4f9de0693e87/Untitled.png)

- 포맷의 유지보수가 어려워진다.

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/60ff2416-d82b-495c-b067-b23520e7c61b/Untitled.png)

- LinkedIn에서 개발해서 지금은 오픈소스로 사용된다.

SourceApplication과 TargetApplication이 쉽게 데이터를 관리할 수 있도록 만들어졌다.

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/6e90e21c-1979-4e16-908d-f1d75a124bab/Untitled.png)

Kafka는 Topic이라는 큐를 갖는다.

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/90af0f4c-f662-454d-b3a6-bc1f58c39327/Untitled.png)

둘 다 라이브러리로 되어있어서 쉽게 적용할 수 있다.

# Topic

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/2fd13d4b-6e0b-4d40-aea3-c10793f72e69/Untitled.png)

- Topic의 이름을 통해서 관리할 수 있다. → 유지보수
- 하나의 토픽은 여러개의 파티션 가능, 파티션에서 데이터를 순서대로 가져가서 사용한다.

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/c875449d-77ec-409d-a07f-ec4d79a03a13/Untitled.png)

- 새로운 Consumer가 생기면 해당 파티션을 가져갈 수 있다.
- 파티션이 여러개일 경우 큐애 쌓을 때

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/1debf8d9-ed97-49ce-bd84-51bb356a13d8/Untitled.png)

- 파티션을 늘리는건 가능한데 줄일 수는 없다.
- 파티션을 늘리면 Consumer의 개수를 늘려서 데이터를 분산시킬 수 있다.
- 보존 기간 설정으로 파티션 내부의 데이터를 관리할 수 있다.

# Producer

- Topic에 해당하는 메시지를 생성
- 특정 Topic으로 데이터를 publish
- 처리 실패 / 재시도 를 처리할 수 있다.

kafak를 주입받을 때 version을 맞춰서 설정해야 한다.

client와 broker의 하위호환성을 고려해서 설정한다.

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/5fc34203-6dcc-451f-9d05-44fb632cf13e/Untitled.png)

- config를 설정한다.

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/b15d19be-e726-404f-8a60-6dd966fdaf10/Untitled.png)

- key를 지정하면 해당 partition에 적재하게 된다.
- 새로운 partition을 추가하는 순간 key와 파티션 매칭이 깨지기 때문에 연결은 보장되지 않습니다.
- 추후에 파티션을 생성하지 않는 것을 추천합니다.

# Broker, Replication, ISR

- Broker는 카프카가 설치된 서버를 의미한다.

- replication의 숫자로 복제본 개수를 관리할 수 있다.

  - broker의 개수에 따라서 제한된다.

  ![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/b28fdc33-f302-49d2-8c08-c023516cf49a/Untitled.png)

- 원본은 LeaderPartition, 복제본은 Follower Partition

- 두개를 합쳐서 In Sync Replica → ISR이라고 부른다.

## Replication & ack

만약

ack: 0

- 응답값이 안온다

ack:1

- LeaderPartition에 전달 후에 응답값을 받는다.
- Replication 관련되서는 받지 않음

ack: all

- follwerPartition에도 전달이 된 경우에 대한 응답값을 받는다.
- 데이터 유실은 없지만 확인하는 부분이 많아 속도가 현저히 느리다.

Replication이 많아지면 브로커의 리소스 사용량이 늘어나므로 최적화하여 사용하는 것이 중요하다.

3개 이상의 브로커를 사용할 때 replication은 3을 추천한다.

# Consumer

- 카프카에서는 Consumer가 데이터를 가져가도 사라지지 않는다.
- 데이터를 가져오는 것을 Polling

## 역할

1. Topic의 Partition으로 부터 데이터 Polling
2. Partition offset 위치 기록(commit)
3. Consumer group을 통해 병렬처리

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/138d9afd-571d-426c-a79a-681ce6391063/Untitled.png)

1. Properties를 통해 환경 설정
2. Consumer 그룹을 지정한다.
3. KafkaConsumer를 생성해서 어느 브로커에서 가져올지 설정한다.
4. 어느 토픽에서 받아올지 결정한다, Partition에서 가져오려면 `assign()` 이용
5. poll은 500ms 만큼 데이터를 기다리고 없을 경우 빈 값의 records를 반환한다.

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/79a465ca-1a1f-41df-81a3-83093367d862/Untitled.png)

- 각 파티션에서 고유한 번호를 붙이는데 이를 offset이라고 부른다.
- offset은 토픽 별로 , 파티션 별로 별개로 지정된다.

consumer_offset을 알고 있으므로 애플리케이션이 실행중에 중지가 되더라도 시작 위치부터 다시 처리할 수 있다.

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/75574ddf-042b-4319-a787-cdd4f986277b/Untitled.png)

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/39c2cbc5-b01d-4241-8914-2724c84ab87f/Untitled.png)

consumer_offset에서 Consumer 그룹별로 토픽별로 offset을 나누어 저장하기 때문에 데이터를 읽는데 문제가 생기지 않는다.